\chapter{Conclusiones}


% Motivación

La motivación principal de este trabajo está en la construcción de modelos reducidos adaptativos, los cuales son modelos sustitutos precisos y muy rápidos de evaluar. Como resultado de utilizar estos modelos se espera acelerar el proceso de inferencia de parámetros al momento de realizar la detección de una onda gravitacional.  

% Objetivo y hp-greedy

El trabajo realizado en esta tesis, sin embargo, consiste en la primera etapa de la construcción de un modelo sustituto predictivo. Esta etapa se refiere a la construcción de bases reducidas con refinamiento \textit{hp-greedy}, que resulta en una estructura de árbol binario que divide al espacio de parámetros en varios subdominios. Como resultado, en lugar de tener una base global para un dado espacio, se tienen varias bases locales, cada una asignada a un subdominio del espacio (las hojas del árbol). Esto es deseable porque las bases locales no necesitan tantos elementos como una base global para obtener un mismo error de representación, y esto se traduce en que el tiempo de cómputo necesario para representar un dado espacio se disminuye notablemente. Luego se espera que esto se traduzca a un modelo más rápido de evaluar.

% problemática


El problema de las bases reducidas \textit{hp-greedy} es que añaden una complejidad extra que no estaba presente en la construcción de las bases reducidas tradicionales. Esta complejidad es la de los hiperparámetros, pues existen múltiples configuraciones de estos que dan lugar a bases con mejor o peor rendimiento.

% Optimización

Este problema se atacó utilizando métodos de optimización bayesiana, o más específicamente, el algoritmo TPE implementado en la librería Optuna, que construye dos densidades de probabilidad en base a las observaciones realizadas, dividiendo el espacio de hiperparámetros en dos; uno ``bueno'' y otro ``malo'' a partir de un error de referencia $y^*$. Luego se maximiza la probabilidad de que la siguiente configuración de hiperparámetros evaluada de lugar a un error por debajo de $y^*$, es decir, que sea una ``buena'' evaluación. De esta forma se reduce la cantidad de configuraciones de hiperparámetros que deberán probarse hasta encontrar un valor óptimo.

% Resultados

Se comparó TPE con métodos clásicos como la búsqueda aleatoria y la búsqueda exhaustiva (\textit{grid search}). Los resultados mostraron que el valor óptimo obtenido con TPE se encuentra en un tiempo dos ordenes de magnitud por debajo que el tiempo de búsqueda exhaustiva en el caso más sencillo, siendo esta diferencia de por lo menos tres ordenes de magnitud en el caso más complejo visto en este trabajo. Esto es una diferencia entre horas y años, por lo que la búsqueda exhaustiva no es una opción viable en los espacios de hiperparámetros medianamente complejos. En el caso de la optimización aleatoria, si bien los resultados no fueron negativos, la velocidad de convergencia al valor óptimo es menor que al usar TPE, debido a que es una búsqueda a ciegas.


Al comparar la construcción de una base reducida global (tradicional) con la construcción de una base reducida \textit{hp-greedy}, un aspecto negativo que salta a la luz es el incremento en el tiempo necesario para construir esta última teniendo en cuenta el tiempo necesario para la optimización de hiperparámetros. Esto repercutirá directamente en el tiempo necesario para entrenar el modelo predictivo final. Sin embargo, con esto se espera dar lugar a un modelo predictivo mucho más rápido de evaluar, que es justamente lo que se busca conseguir.

% Optimización Multiobjetivo

Por último, la optimización multiobjetivo no resultó de mucho interés en este contexto debido a la gran correlación entre $n_{max}$ y el tiempo de proyección. Este resultado cae dentro de lo esperado, como se explica en la sección \ref{sec:corr_t}.

% Final

En conclusión, la optimización de hiperparámetros demostró ser un componente fundamental en la construcción de una base reducida \textit{hp-greedy}, logrando muy buenos resultados aplicando optimización bayesiana, o más específicamente, el algoritmo TPE implementado en Optuna.

\subsection*{Trabajo a Futuro}

% robustez

Si bien las optimizaciones realizadas mostraron muy buenos resultados, aún se podría investigar la robustez de los hiperparámetros con métodos de análisis de sensibilidad (los cuales son costosos de evaluar). Una configuración de hiperparámetros puede ser óptima pero inestable, es decir que se pierde la optimalidad al desplazarse un valor tan pequeño como se quiera. Esto no ocurre en el caso de configuraciones que sean óptimas y robustas. Por lo tanto un trabajo a futuro será analizar la robustez de los valores óptimos obtenidos con tests de análisis de sensibilidad.

% otros métodos

Otro tema de interés es probar otros métodos de optimización fuera del marco de la optimización bayesiana convencional, como son los algoritmos evolutivos o genéticos, o metodologías más modernas como hyperbandid \cite{li_hyperband_2018}.

% Modelo Final

Por último, como se mencionó anteriormente, la construcción de una base reducida \textit{hp-greedy} óptima constituye solamente el primer paso en la construcción de un modelo sustituto capaz de realizar predicciones. Por lo tanto aún queda el trabajo de implementar el modelo final.



