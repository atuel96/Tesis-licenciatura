\chapter{Conclusión}

Las bases reducidas con refinamiento \textit{hp-greedy} mostraron una clara ventaja con respecto a las bases reducidas globales. Para obtener un mismo error máximo de validación, una base local necesita muchos más elementos, lo que se traduce en un mayor tiempo requerido para proyectar un espacio.

El problema de las bases reducidas \textit{hp-greedy}, que no está presente en la construcción de una base reducida global, es la complejidad añadida debido al gran número de configuraciones de hiperparámetros que afectan al rendimiento final. 

%La optimización de hiperparámetros es un problema que ha tenido un gran desarrollo en los últimos años debdio a la necesidad de construir modelos cada vez más complejos dentro del área de aprendizaje supervisado y aprendizaje profundo.

En este trabajó se utilizaron métodos de optimización bayesiana para resolver el problema de la selección de hiperparámetros, y se lograron resultados que cumplieron con las espectativas iniciales. Se observó que para los hiperparámetros más relevantes se necesitaban relativamente pocas iteraciones hasta que alcanzar una convergencia.

También se puso a prueba la optimización por búsqueda aleatoria, con buenos pero inferiores resultados, y se mostró que la búsqueda exhaustiva, si bien garantiza un resultado óptimo, requeriría un tiempo prohibitivo para ser puesta en práctica en un escenario realista.


Por últimoi,una opción interesante fue la optimización multiobjetivo, que permitió optimizar el error de representación al mismo tiempo que el tiempo de proyección. Sin embargo la gran correlación que hay entre el segundo objetivo y $n_{max}$ hace que el aporte de este método no esté a la altura de la complejidad extra que surge del mismo. Pues para limitar el tiempo de proyección simplemente se limita el máximo valor de $n_{max}$ dentro de la optimización a realizar.



